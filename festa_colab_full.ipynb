{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FESTA Experiment on Google Colab - Full Dataset\n",
    "\n",
    "**Processing 100 samples per task (300 total samples)**\n",
    "\n",
    "This notebook runs the FESTA (Feature-Equivalent and Semantically-Targeted Augmentation) experiment on the TREA dataset stored in Google Drive.\n",
    "\n",
    "## Features:\n",
    "- ‚úÖ Dataset stored in Google Drive (upload once, use always)\n",
    "- ‚úÖ Checkpoint/resume capability (survives session timeouts)\n",
    "- ‚úÖ Results saved to Drive automatically\n",
    "- ‚úÖ GPU memory optimization\n",
    "- ‚úÖ Progress tracking and monitoring\n",
    "\n",
    "## Expected Runtime:\n",
    "- **Total samples**: 300 (100 per task)\n",
    "- **Estimated time**: 5-8 hours on Colab GPU\n",
    "- **Per sample**: ~1-2 minutes\n",
    "\n",
    "## Prerequisites:\n",
    "1. TREA_dataset folder uploaded to Google Drive root (`My Drive/TREA_dataset`)\n",
    "2. Colab with GPU runtime (Runtime > Change runtime type > GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Mount Google Drive\n",
    "\n",
    "This will prompt you to authorize access to your Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"‚úÖ Google Drive mounted successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Verify GPU and System Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Verify Dataset in Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Check if dataset exists in Drive\n",
    "dataset_path = Path(\"/content/drive/MyDrive/TREA_dataset\")\n",
    "\n",
    "if not dataset_path.exists():\n",
    "    print(\"‚ùå ERROR: TREA_dataset folder not found in Google Drive!\")\n",
    "    print(\"\\nüìã Please follow these steps:\")\n",
    "    print(\"   1. Upload the TREA_dataset folder to 'My Drive' (root level)\")\n",
    "    print(\"   2. Wait for upload to complete\")\n",
    "    print(\"   3. Re-run this cell\")\n",
    "    raise FileNotFoundError(\"Dataset not found in Google Drive\")\n",
    "\n",
    "print(\"‚úÖ Dataset found in Google Drive!\")\n",
    "print(f\"\\nüìÅ Dataset location: {dataset_path}\")\n",
    "print(\"\\nüìä Dataset structure:\")\n",
    "\n",
    "# Check each task folder\n",
    "for task in [\"count\", \"order\", \"duration\"]:\n",
    "    task_dir = dataset_path / task\n",
    "    csv_file = task_dir / f\"{task}.csv\"\n",
    "    \n",
    "    if csv_file.exists():\n",
    "        # Count lines (samples)\n",
    "        with open(csv_file, 'r') as f:\n",
    "            num_samples = len(f.readlines()) - 1  # -1 for header\n",
    "        print(f\"  ‚úÖ {task}: {num_samples} samples\")\n",
    "    else:\n",
    "        print(f\"  ‚ùå {task}: CSV file not found\")\n",
    "\n",
    "print(\"\\n‚úÖ All dataset files verified!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Clone Repository and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "!git clone https://github.com/atinmathur/AudioLLM-FESTA.git /content/AudioLLM-FESTA\n",
    "\n",
    "%cd /content/AudioLLM-FESTA\n",
    "\n",
    "print(\"‚úÖ Repository ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q transformers>=4.37.0\n",
    "!pip install -q torch torchaudio\n",
    "!pip install -q librosa soundfile\n",
    "!pip install -q pandas numpy scikit-learn\n",
    "!pip install -q pyyaml tqdm\n",
    "!pip install -q qwen-audio-chat  # Qwen2-Audio specific\n",
    "\n",
    "print(\"‚úÖ All dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Copy Config to Repository\n",
    "\n",
    "Copy the full dataset config file to the repository directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If config_colab_full.yaml is in the repo, it's already there\n",
    "# Otherwise, create it here:\n",
    "\n",
    "import yaml\n",
    "\n",
    "config = {\n",
    "    'model': {\n",
    "        'name': 'Qwen/Qwen2-Audio-7B-Instruct',\n",
    "        'device': 'cuda',\n",
    "        'dtype': 'float16',\n",
    "        'max_length': 512\n",
    "    },\n",
    "    'dataset': {\n",
    "        'data_dir': '/content/drive/MyDrive/TREA_dataset',\n",
    "        'tasks': ['count', 'order', 'duration'],\n",
    "        'samples_per_task': 100,\n",
    "        'random_seed': 42\n",
    "    },\n",
    "    'festa': {\n",
    "        'n_fes_audio': 5,\n",
    "        'n_fes_text': 2,\n",
    "        'n_fcs_audio': 5,\n",
    "        'n_fcs_text': 2\n",
    "    },\n",
    "    'fes_transforms': {\n",
    "        'audio': [\n",
    "            {'type': 'add_silence', 'params': {'duration_range': [0.1, 0.3], 'position': 'between'}},\n",
    "            {'type': 'volume_adjustment', 'params': {'gain_range': [-0.15, 0.15]}},\n",
    "            {'type': 'add_noise', 'params': {'snr_range': [30, 40]}}\n",
    "        ],\n",
    "        'text': {'paraphrase_method': 'manual', 'num_paraphrases': 2}\n",
    "    },\n",
    "    'fcs_transforms': {\n",
    "        'count': {'audio': [{'type': 'add_event', 'params': {'source': 'synthetic_silences', 'position': ['start', 'end']}}]},\n",
    "        'order': {'audio': [{'type': 'swap_events', 'params': {'mode': 'adjacent'}}]},\n",
    "        'duration': {'audio': [{'type': 'replace_event', 'params': {'target': ['longest', 'shortest']}}]},\n",
    "        'text': {'reverse_relationships': True, 'avoid_negation': True}\n",
    "    },\n",
    "    'baselines': {\n",
    "        'output_entropy': {'enabled': True, 'temperature': 1.0, 'num_samples': 10},\n",
    "        'verbalized_confidence': {'enabled': False},\n",
    "        'input_augmentation': {'enabled': False},\n",
    "        'rephrase_uncertainty': {'enabled': True, 'num_rephrases': 3},\n",
    "        'blackbox_uncertainty': {'enabled': False}\n",
    "    },\n",
    "    'metrics': ['auroc', 'accuracy', 'selective_risk', 'coverage_accuracy'],\n",
    "    'experiment': {\n",
    "        'output_dir': '/content/drive/MyDrive/festa_results',\n",
    "        'save_predictions': True,\n",
    "        'save_uncertainty_scores': True,\n",
    "        'save_intermediate': True,\n",
    "        'checkpoint_file': '/content/drive/MyDrive/festa_checkpoint.json',\n",
    "        'log_level': 'INFO'\n",
    "    },\n",
    "    'hardware': {\n",
    "        'batch_size': 1,\n",
    "        'num_workers': 2,\n",
    "        'pin_memory': True,\n",
    "        'clear_cache': True\n",
    "    },\n",
    "    'colab': {\n",
    "        'auto_save_interval': 1,\n",
    "        'memory_monitor': True,\n",
    "        'test_mode': False\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save config\n",
    "with open('config_colab_full.yaml', 'w') as f:\n",
    "    yaml.dump(config, f, default_flow_style=False)\n",
    "\n",
    "print(\"‚úÖ Config file created: config_colab_full.yaml\")\n",
    "print(f\"   - Dataset: 100 samples per task (300 total)\")\n",
    "print(f\"   - Results will be saved to: /content/drive/MyDrive/festa_results\")\n",
    "print(f\"   - Checkpoint: /content/drive/MyDrive/festa_checkpoint.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Check Existing Progress (Resume Capability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "checkpoint_file = Path(\"/content/drive/MyDrive/festa_checkpoint.json\")\n",
    "\n",
    "if checkpoint_file.exists():\n",
    "    with open(checkpoint_file, 'r') as f:\n",
    "        checkpoint = json.load(f)\n",
    "    \n",
    "    completed = len(checkpoint.get('completed_sample_ids', []))\n",
    "    total = checkpoint.get('total_samples', 300)\n",
    "    progress = checkpoint.get('progress_percent', 0)\n",
    "    \n",
    "    print(\"üìÇ Found existing checkpoint!\")\n",
    "    print(f\"   Progress: {completed}/{total} samples ({progress:.1f}%)\")\n",
    "    print(f\"   Last updated: {checkpoint.get('last_updated', 'Unknown')}\")\n",
    "    print(\"\\n‚úÖ Experiment will resume from where it left off\")\n",
    "else:\n",
    "    print(\"üìù No checkpoint found - starting fresh\")\n",
    "    print(\"   Will process all 300 samples (100 per task)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Run FESTA Experiment\n",
    "\n",
    "**‚ö†Ô∏è IMPORTANT:**\n",
    "- This will take **5-8 hours** to complete\n",
    "- Progress is saved after each sample\n",
    "- If Colab disconnects, just re-run this cell to resume\n",
    "- Results are saved to Google Drive automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the experiment\n",
    "!python experiments/run_festa_colab.py --config config_colab_full.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Monitor Progress (Run this in a separate cell while experiment is running)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "from IPython.display import clear_output\n",
    "\n",
    "checkpoint_file = Path(\"/content/drive/MyDrive/festa_checkpoint.json\")\n",
    "\n",
    "# Monitor for 60 iterations (5 minutes if checking every 5 seconds)\n",
    "for i in range(60):\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    if checkpoint_file.exists():\n",
    "        with open(checkpoint_file, 'r') as f:\n",
    "            checkpoint = json.load(f)\n",
    "        \n",
    "        completed = len(checkpoint.get('completed_sample_ids', []))\n",
    "        total = checkpoint.get('total_samples', 300)\n",
    "        progress = checkpoint.get('progress_percent', 0)\n",
    "        \n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"üîÑ FESTA Experiment Progress\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"üìä Samples: {completed}/{total} ({progress:.1f}%)\")\n",
    "        print(f\"‚è±Ô∏è  Last updated: {checkpoint.get('last_updated', 'Unknown')}\")\n",
    "        \n",
    "        # Progress bar\n",
    "        bar_length = 40\n",
    "        filled = int(bar_length * completed / total)\n",
    "        bar = '‚ñà' * filled + '‚ñë' * (bar_length - filled)\n",
    "        print(f\"\\n[{bar}]\")\n",
    "        \n",
    "        if completed == total:\n",
    "            print(\"\\nüéâ Experiment completed!\")\n",
    "            break\n",
    "    else:\n",
    "        print(\"‚è≥ Waiting for experiment to start...\")\n",
    "    \n",
    "    time.sleep(5)  # Check every 5 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import glob\n",
    "\n",
    "results_dir = Path(\"/content/drive/MyDrive/festa_results\")\n",
    "\n",
    "if not results_dir.exists():\n",
    "    print(\"‚ùå Results directory not found. Run the experiment first.\")\n",
    "else:\n",
    "    print(f\"üìÅ Results directory: {results_dir}\\n\")\n",
    "    \n",
    "    # List all result files\n",
    "    result_files = list(results_dir.glob(\"*.json\"))\n",
    "    \n",
    "    if not result_files:\n",
    "        print(\"‚è≥ No results yet. Experiment still running...\")\n",
    "    else:\n",
    "        print(f\"üìä Found {len(result_files)} result files:\\n\")\n",
    "        \n",
    "        for f in sorted(result_files):\n",
    "            print(f\"  ‚Ä¢ {f.name}\")\n",
    "        \n",
    "        # Try to load latest metrics\n",
    "        metrics_files = sorted(results_dir.glob(\"metrics_*.json\"))\n",
    "        if metrics_files:\n",
    "            latest_metrics = metrics_files[-1]\n",
    "            with open(latest_metrics, 'r') as f:\n",
    "                metrics = json.load(f)\n",
    "            \n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"üìà Latest Results\")\n",
    "            print(f\"{'='*60}\")\n",
    "            \n",
    "            if 'overall_accuracy' in metrics:\n",
    "                print(f\"Overall Accuracy: {metrics['overall_accuracy']:.2%}\")\n",
    "            \n",
    "            if 'method_results' in metrics:\n",
    "                print(\"\\nMethod AUROC Scores:\")\n",
    "                for method, results in metrics['method_results'].items():\n",
    "                    auroc = results.get('auroc', 'N/A')\n",
    "                    if isinstance(auroc, float):\n",
    "                        print(f\"  {method}: {auroc:.4f}\")\n",
    "                    else:\n",
    "                        print(f\"  {method}: {auroc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Download Results (Optional)\n",
    "\n",
    "Results are already in Google Drive, but you can download them to your local machine if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "results_dir = Path(\"/content/drive/MyDrive/festa_results\")\n",
    "\n",
    "if results_dir.exists():\n",
    "    # Create a zip file\n",
    "    zip_path = \"/content/festa_results.zip\"\n",
    "    shutil.make_archive(\"/content/festa_results\", 'zip', results_dir)\n",
    "    \n",
    "    print(\"üì¶ Created zip file of results\")\n",
    "    print(\"‚¨áÔ∏è  Downloading...\")\n",
    "    \n",
    "    files.download(zip_path)\n",
    "    \n",
    "    print(\"‚úÖ Download complete!\")\n",
    "else:\n",
    "    print(\"‚ùå No results to download yet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 11. Resume from Checkpoint (If Session Disconnected)\n",
    "\n",
    "If your Colab session times out or disconnects:\n",
    "\n",
    "1. **Re-run cells 1-6** (Mount Drive, verify dataset, install dependencies)\n",
    "2. **Check cell 6** to see your progress\n",
    "3. **Re-run cell 7** - it will automatically resume from the last checkpoint\n",
    "\n",
    "The checkpoint system ensures no work is lost!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Notes\n",
    "\n",
    "### File Locations:\n",
    "- **Dataset**: `/content/drive/MyDrive/TREA_dataset`\n",
    "- **Results**: `/content/drive/MyDrive/festa_results`\n",
    "- **Checkpoint**: `/content/drive/MyDrive/festa_checkpoint.json`\n",
    "\n",
    "### Troubleshooting:\n",
    "- **Out of memory**: The code already clears GPU cache between samples. If still OOM, reduce `n_fes_audio` or `n_fcs_audio` in config.\n",
    "- **Dataset not found**: Make sure TREA_dataset is in the root of 'My Drive', not in a subfolder\n",
    "- **Slow progress**: Each sample takes 1-2 minutes. Total runtime: 5-8 hours for 300 samples.\n",
    "\n",
    "### Monitoring:\n",
    "- Check GPU usage: Run cell 2 anytime\n",
    "- Monitor progress: Run cell 8 while experiment runs\n",
    "- View checkpoint: Run cell 6 anytime"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
