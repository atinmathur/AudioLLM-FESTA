{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FESTA: Audio LLM Uncertainty Estimation on Google Colab\n",
    "\n",
    "This notebook runs the FESTA (Functionally Equivalent Sampling for Trust Assessment) framework on Google Colab.\n",
    "\n",
    "## Contents\n",
    "1. **Environment Setup** - Install dependencies and verify GPU\n",
    "2. **Upload Files** - Upload your code and dataset\n",
    "3. **Configuration** - Set up paths and parameters\n",
    "4. **Model Loading** - Download and load Qwen2-Audio model\n",
    "5. **Run Experiment** - Execute FESTA pipeline\n",
    "6. **View Results** - Analyze and visualize results\n",
    "7. **Download Results** - Package and download outputs\n",
    "\n",
    "## Quick Start\n",
    "1. **Enable GPU**: Runtime ‚Üí Change runtime type ‚Üí GPU (T4 or better)\n",
    "2. **Run all cells**: Runtime ‚Üí Run all\n",
    "3. **Upload files** when prompted\n",
    "4. **Wait ~10-15 minutes** for completion\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "\n",
    "First, let's check GPU availability and install dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è WARNING: No GPU detected! This will be very slow on CPU.\")\n",
    "    print(\"Please enable GPU: Runtime ‚Üí Change runtime type ‚Üí GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install system dependencies\n",
    "print(\"Installing system dependencies...\")\n",
    "!apt-get update -qq\n",
    "!apt-get install -y -qq ffmpeg libsndfile1\n",
    "print(\"‚úÖ System dependencies installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Python packages\n",
    "print(\"Installing Python packages (this may take 2-3 minutes)...\\n\")\n",
    "\n",
    "# Core ML packages\n",
    "!pip install -q torch torchvision torchaudio\n",
    "!pip install -q transformers>=4.40.0 accelerate>=0.27.0\n",
    "!pip install -q sentencepiece protobuf\n",
    "\n",
    "# Audio processing\n",
    "!pip install -q librosa soundfile pydub audioread\n",
    "\n",
    "# Data and visualization\n",
    "!pip install -q numpy pandas scikit-learn\n",
    "!pip install -q matplotlib seaborn plotly\n",
    "\n",
    "# Utilities\n",
    "!pip install -q tqdm pyyaml opencv-python\n",
    "\n",
    "print(\"\\n‚úÖ All packages installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify installations\n",
    "print(\"Verifying installations...\\n\")\n",
    "\n",
    "import sys\n",
    "packages = [\n",
    "    'torch', 'transformers', 'librosa', 'soundfile', \n",
    "    'numpy', 'pandas', 'sklearn', 'matplotlib', 'tqdm', 'yaml'\n",
    "]\n",
    "\n",
    "all_good = True\n",
    "for pkg in packages:\n",
    "    try:\n",
    "        __import__(pkg)\n",
    "        print(f\"‚úÖ {pkg}\")\n",
    "    except ImportError:\n",
    "        print(f\"‚ùå {pkg} - FAILED\")\n",
    "        all_good = False\n",
    "\n",
    "if all_good:\n",
    "    print(\"\\nüéâ All packages verified!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Some packages failed. Please re-run the installation cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Upload Files\n",
    "\n",
    "Upload your AudioLLM-FESTA project to Colab.\n",
    "\n",
    "### ‚ö° Recommended: Use Mini Dataset (Fast Upload!)\n",
    "\n",
    "The full TREA dataset is **908MB** and takes 20-30 minutes to upload. For quick testing, use the **mini dataset** instead:\n",
    "\n",
    "```bash\n",
    "# On your local machine (in AudioLLM-FESTA directory):\n",
    "\n",
    "# 1. Generate mini dataset (~30 seconds)\n",
    "python scripts/create_mini_dataset.py\n",
    "\n",
    "# 2. Package for Colab (~10 seconds)\n",
    "python scripts/package_for_colab.py\n",
    "\n",
    "# Output: AudioLLM-FESTA.zip (~25MB)\n",
    "# Upload time: 1-2 minutes ‚ö° (vs 30+ minutes for full dataset)\n",
    "```\n",
    "\n",
    "**What's included in mini dataset:**\n",
    "- ‚úÖ All code (src/, experiments/, notebooks/)\n",
    "- ‚úÖ 15 audio samples (5 per task)\n",
    "- ‚úÖ All configurations\n",
    "- ‚úÖ Full FESTA pipeline works identically\n",
    "- ‚ö†Ô∏è Only for quick testing (not final evaluation)\n",
    "\n",
    "**Upload this**: `AudioLLM-FESTA.zip`\n",
    "\n",
    "---\n",
    "\n",
    "### Alternative: Full Dataset (Slow Upload)\n",
    "\n",
    "If you want to use the full dataset:\n",
    "\n",
    "```bash\n",
    "# On your local machine:\n",
    "# DON'T include TREA_dataset in AudioLLM-FESTA zip (makes it huge!)\n",
    "\n",
    "# Option 1: Exclude dataset from code zip\n",
    "cd path/to/parent/directory\n",
    "zip -r AudioLLM-FESTA.zip AudioLLM-FESTA/ -x \"AudioLLM-FESTA/TREA_dataset/*\"\n",
    "\n",
    "# Option 2: Upload to Google Drive instead (one-time, recommended)\n",
    "# Upload TREA_dataset to Drive, then mount in Colab (see below)\n",
    "```\n",
    "\n",
    "**For first-time users**: Use mini dataset! You can scale up later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import files\n",
    "\n",
    "print(\"üì§ Please upload your file:\")\n",
    "print(\"  ‚Ä¢ AudioLLM-FESTA.zip (recommended - mini dataset, ~25MB)\")\n",
    "print(\"  OR\")\n",
    "print(\"  ‚Ä¢ AudioLLM-FESTA.zip + TREA_dataset.zip (full dataset, ~900MB+)\\n\")\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "print(\"\\nüì¶ Files uploaded:\")\n",
    "for filename in uploaded.keys():\n",
    "    print(f\"  ‚Ä¢ {filename} ({len(uploaded[filename]) / 1024**2:.2f} MB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract zip files if uploaded\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"üì¶ Extracting files...\\n\")\n",
    "\n",
    "for filename in uploaded.keys():\n",
    "    if filename.endswith('.zip'):\n",
    "        print(f\"Extracting {filename}...\")\n",
    "        with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "            zip_ref.extractall('/content/')\n",
    "        print(f\"  ‚úÖ Extracted to /content/\")\n",
    "        \n",
    "        # Remove zip file to save space\n",
    "        os.remove(filename)\n",
    "        print(f\"  üóëÔ∏è  Removed {filename}\")\n",
    "\n",
    "print(\"\\n‚úÖ All files extracted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify directory structure and dataset type\n",
    "print(\"üìÇ Verifying directory structure...\\n\")\n",
    "\n",
    "required_paths = [\n",
    "    '/content/AudioLLM-FESTA',\n",
    "    '/content/AudioLLM-FESTA/src',\n",
    "    '/content/AudioLLM-FESTA/experiments',\n",
    "    '/content/AudioLLM-FESTA/TREA_dataset',\n",
    "    '/content/AudioLLM-FESTA/TREA_dataset/count',\n",
    "    '/content/AudioLLM-FESTA/TREA_dataset/order',\n",
    "    '/content/AudioLLM-FESTA/TREA_dataset/duration',\n",
    "]\n",
    "\n",
    "all_exist = True\n",
    "for path in required_paths:\n",
    "    if os.path.exists(path):\n",
    "        print(f\"‚úÖ {path}\")\n",
    "    else:\n",
    "        print(f\"‚ùå {path} - NOT FOUND\")\n",
    "        all_exist = False\n",
    "\n",
    "# Check dataset size\n",
    "if all_exist:\n",
    "    dataset_path = Path('/content/AudioLLM-FESTA/TREA_dataset')\n",
    "    audio_files = list(dataset_path.rglob('*.wav'))\n",
    "    total_files = len(audio_files)\n",
    "    \n",
    "    print(f\"\\nüìä Dataset Information:\")\n",
    "    print(f\"  Total audio files: {total_files}\")\n",
    "    \n",
    "    if total_files <= 30:\n",
    "        print(f\"  Dataset type: ‚ú® MINI DATASET (fast upload!)\")\n",
    "        print(f\"  Best for: Quick testing and verification\")\n",
    "        print(f\"  Samples per task: ~{total_files // 3}\")\n",
    "    else:\n",
    "        print(f\"  Dataset type: üì¶ FULL DATASET\")\n",
    "        print(f\"  Best for: Final experiments and evaluation\")\n",
    "        print(f\"  Samples per task: ~{total_files // 3}\")\n",
    "    \n",
    "    print(\"\\nüéâ Directory structure verified!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Some directories missing. Please check your upload.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show directory tree\n",
    "!tree -L 2 /content/AudioLLM-FESTA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configuration\n",
    "\n",
    "Set up paths and load configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to project directory\n",
    "import os\n",
    "os.chdir('/content/AudioLLM-FESTA')\n",
    "print(f\"Current directory: {os.getcwd()}\")\n",
    "\n",
    "# Add to Python path\n",
    "import sys\n",
    "sys.path.insert(0, '/content/AudioLLM-FESTA')\n",
    "print(\"‚úÖ Python path updated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display configuration\n",
    "import yaml\n",
    "\n",
    "config_path = 'config_colab.yaml'\n",
    "\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"üìã Current Configuration:\\n\")\n",
    "print(f\"Model: {config['model']['name']}\")\n",
    "print(f\"Device: {config['model']['device']}\")\n",
    "print(f\"Dtype: {config['model']['dtype']}\")\n",
    "print(f\"\\nDataset:\")\n",
    "print(f\"  Samples per task: {config['dataset']['samples_per_task']}\")\n",
    "print(f\"  Tasks: {config['dataset']['tasks']}\")\n",
    "print(f\"\\nFESTA Sampling:\")\n",
    "print(f\"  FES: {config['festa']['n_fes_audio']} audio √ó {config['festa']['n_fes_text']} text = {config['festa']['n_fes_audio'] * config['festa']['n_fes_text']} samples\")\n",
    "print(f\"  FCS: {config['festa']['n_fcs_audio']} audio √ó {config['festa']['n_fcs_text']} text = {config['festa']['n_fcs_audio'] * config['festa']['n_fcs_text']} samples\")\n",
    "print(f\"\\nEstimated runtime: ~10-15 minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Modify configuration for even faster testing\n",
    "# Uncomment to run in TEST MODE (1 sample only)\n",
    "\n",
    "# config['colab']['test_mode'] = True\n",
    "# with open(config_path, 'w') as f:\n",
    "#     yaml.safe_dump(config, f)\n",
    "# print(\"üß™ TEST MODE ENABLED - Will process only 1 sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test imports\n",
    "print(\"Testing FESTA imports...\\n\")\n",
    "\n",
    "try:\n",
    "    from src.data_loader import load_trea_dataset\n",
    "    print(\"‚úÖ data_loader\")\n",
    "    \n",
    "    from src.model_wrapper import Qwen2AudioWrapper\n",
    "    print(\"‚úÖ model_wrapper\")\n",
    "    \n",
    "    from src.fes_generator import FESGenerator\n",
    "    print(\"‚úÖ fes_generator\")\n",
    "    \n",
    "    from src.fcs_generator import FCSGenerator\n",
    "    print(\"‚úÖ fcs_generator\")\n",
    "    \n",
    "    from src.uncertainty import FESTAUncertainty\n",
    "    print(\"‚úÖ uncertainty\")\n",
    "    \n",
    "    from src.metrics import compute_auroc, compute_accuracy\n",
    "    print(\"‚úÖ metrics\")\n",
    "    \n",
    "    from src.baselines import BaselineUncertainty\n",
    "    print(\"‚úÖ baselines\")\n",
    "    \n",
    "    print(\"\\nüéâ All FESTA modules imported successfully!\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"\\n‚ùå Import error: {e}\")\n",
    "    print(\"Please check that all files were uploaded correctly.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Loading\n",
    "\n",
    "Download and load the Qwen2-Audio-7B-Instruct model (~14GB).\n",
    "\n",
    "**Note**: This will take 5-10 minutes on first run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check available disk space\n",
    "!df -h /content\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è Model download requires ~14GB\")\n",
    "print(\"Please ensure you have sufficient space.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model loading (downloads model on first run)\n",
    "from src.model_wrapper import Qwen2AudioWrapper\n",
    "import torch\n",
    "\n",
    "print(\"ü§ñ Loading Qwen2-Audio model...\")\n",
    "print(\"This will download ~14GB on first run (5-10 minutes)\\n\")\n",
    "\n",
    "model = Qwen2AudioWrapper(\n",
    "    model_name=\"Qwen/Qwen2-Audio-7B-Instruct\",\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    dtype=\"float16\",\n",
    "    max_length=512\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Model loaded successfully!\")\n",
    "print(f\"\\nModel info:\")\n",
    "info = model.get_model_info()\n",
    "for key, value in info.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick test prediction\n",
    "from src.data_loader import load_trea_dataset\n",
    "\n",
    "print(\"üß™ Testing model prediction...\\n\")\n",
    "\n",
    "# Load one sample\n",
    "dataset = load_trea_dataset(\n",
    "    data_dir='TREA_dataset',\n",
    "    samples_per_task=1,\n",
    "    random_seed=42\n",
    ")\n",
    "\n",
    "sample = dataset.data[0]\n",
    "print(f\"Task: {sample['task']}\")\n",
    "print(f\"Question: {sample['question']}\")\n",
    "print(f\"Options: {sample['options']}\")\n",
    "print(f\"Ground Truth: {sample['correct_answer']}\\n\")\n",
    "\n",
    "# Get prediction\n",
    "prediction, probs = model.predict(\n",
    "    sample['audio_path'],\n",
    "    sample['question'],\n",
    "    sample['options'],\n",
    "    return_probs=True\n",
    ")\n",
    "\n",
    "print(f\"Prediction: {prediction}\")\n",
    "print(f\"Correct: {'‚úÖ YES' if prediction == sample['correct_answer'] else '‚ùå NO'}\")\n",
    "print(f\"\\nProbabilities:\")\n",
    "for option, prob in sorted(probs.items()):\n",
    "    bar = '‚ñà' * int(prob * 30)\n",
    "    print(f\"  {option}: {prob:.3f} {bar}\")\n",
    "\n",
    "print(\"\\n‚úÖ Model test passed!\")\n",
    "\n",
    "# Cleanup\n",
    "del model\n",
    "torch.cuda.empty_cache()\n",
    "print(\"üßπ Memory cleared\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run FESTA Experiment\n",
    "\n",
    "Run the full FESTA pipeline with checkpoint support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the experiment\n",
    "!python experiments/run_festa_colab.py --config config_colab.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resume from Checkpoint (if disconnected)\n",
    "\n",
    "If your session disconnects, just re-run the cell above. The experiment will automatically resume from where it left off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. View Results\n",
    "\n",
    "Load and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List result files\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "results_dir = Path('/content/festa_results')\n",
    "\n",
    "print(\"üìÅ Result files:\\n\")\n",
    "for file in sorted(results_dir.glob('*.json')):\n",
    "    size = file.stat().st_size / 1024  # KB\n",
    "    print(f\"  ‚Ä¢ {file.name} ({size:.1f} KB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display metrics\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Find latest metrics file\n",
    "metrics_files = sorted(results_dir.glob('metrics_*.json'))\n",
    "if metrics_files:\n",
    "    latest_metrics = metrics_files[-1]\n",
    "    \n",
    "    with open(latest_metrics, 'r') as f:\n",
    "        metrics = json.load(f)\n",
    "    \n",
    "    print(\"üìä FESTA Results Summary\\n\")\n",
    "    print(f\"Overall Accuracy: {metrics['overall_accuracy']:.2%}\\n\")\n",
    "    \n",
    "    print(\"Method Comparison:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    method_results = metrics['method_results']\n",
    "    for method, scores in sorted(method_results.items(), \n",
    "                                  key=lambda x: x[1]['auroc'], \n",
    "                                  reverse=True):\n",
    "        print(f\"{method:<20} AUROC: {scores['auroc']:.4f}\")\n",
    "else:\n",
    "    print(\"No metrics files found. Please run the experiment first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "if metrics_files:\n",
    "    # Create bar plot of AUROC scores\n",
    "    methods = list(method_results.keys())\n",
    "    aurocs = [method_results[m]['auroc'] for m in methods]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(methods, aurocs, color=['#FF6B6B', '#4ECDC4', '#45B7D1'])\n",
    "    plt.xlabel('Method', fontsize=12)\n",
    "    plt.ylabel('AUROC', fontsize=12)\n",
    "    plt.title('Uncertainty Method Comparison', fontsize=14, fontweight='bold')\n",
    "    plt.ylim([0, 1])\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.3f}',\n",
    "                ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('/content/festa_results/auroc_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"‚úÖ Plot saved to: /content/festa_results/auroc_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load predictions and show sample results\n",
    "pred_files = sorted(results_dir.glob('predictions_*.json'))\n",
    "if pred_files:\n",
    "    latest_preds = pred_files[-1]\n",
    "    \n",
    "    with open(latest_preds, 'r') as f:\n",
    "        preds_data = json.load(f)\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'Task': preds_data['tasks'],\n",
    "        'Prediction': preds_data['predictions'],\n",
    "        'Ground Truth': preds_data['ground_truths'],\n",
    "        'Correct': [p == g for p, g in zip(preds_data['predictions'], \n",
    "                                           preds_data['ground_truths'])]\n",
    "    })\n",
    "    \n",
    "    print(\"\\nüìã Sample Predictions:\\n\")\n",
    "    print(df.head(10))\n",
    "    \n",
    "    print(\"\\nüìä Task-wise Accuracy:\")\n",
    "    task_acc = df.groupby('Task')['Correct'].mean()\n",
    "    for task, acc in task_acc.items():\n",
    "        print(f\"  {task}: {acc:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Download Results\n",
    "\n",
    "Package and download all results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create zip file with all results\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "zip_filename = f\"festa_results_{timestamp}.zip\"\n",
    "\n",
    "print(f\"üì¶ Creating results package: {zip_filename}\\n\")\n",
    "\n",
    "shutil.make_archive(\n",
    "    f'/content/festa_results_{timestamp}',\n",
    "    'zip',\n",
    "    '/content/festa_results'\n",
    ")\n",
    "\n",
    "zip_path = f'/content/festa_results_{timestamp}.zip'\n",
    "zip_size = os.path.getsize(zip_path) / 1024  # KB\n",
    "\n",
    "print(f\"‚úÖ Results packaged: {zip_size:.1f} KB\")\n",
    "print(f\"\\nContents:\")\n",
    "!unzip -l {zip_path} | head -20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download results\n",
    "from google.colab import files\n",
    "\n",
    "print(\"‚¨áÔ∏è Downloading results...\")\n",
    "files.download(zip_path)\n",
    "print(\"‚úÖ Download started! Check your browser's download folder.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You've successfully run FESTA on Google Colab! üéâ\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **Scale up**: Change `samples_per_task` to 30 in config_colab.yaml\n",
    "2. **More samples**: Increase `n_fes_audio` and `n_fes_text` to 15 and 4\n",
    "3. **Full baselines**: Enable all baseline methods in config\n",
    "4. **Analysis**: Open the notebooks in `notebooks/` for deeper analysis\n",
    "\n",
    "### Files Generated:\n",
    "- `predictions_*.json` - Model predictions and ground truths\n",
    "- `uncertainties_*.json` - FESTA and baseline uncertainty scores\n",
    "- `metrics_*.json` - AUROC, accuracy, and task-wise metrics\n",
    "- `auroc_comparison.png` - Visualization of method comparison\n",
    "\n",
    "### Expected Performance (from paper):\n",
    "- FESTA AUROC: **0.83-0.91**\n",
    "- Best Baseline: ~0.68-0.71\n",
    "- Improvement: **+30-40%**\n",
    "\n",
    "---\n",
    "\n",
    "**For questions or issues**, refer to:\n",
    "- `README.md` - Full documentation\n",
    "- `QUICK_START.md` - Setup guide\n",
    "- `COLAB_INSTRUCTIONS.md` - Colab-specific instructions"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
